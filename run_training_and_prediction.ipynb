{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1c6149",
   "metadata": {},
   "source": [
    "# Flower Classification - Training and Prediction\n",
    "\n",
    "This notebook demonstrates how to train a deep learning model and make predictions using the command-line scripts.\n",
    "\n",
    "## Project Structure\n",
    "- `train.py` - Training script\n",
    "- `predict.py` - Prediction script\n",
    "- `workspace_utils.py` - Helper functions\n",
    "- `flowers/` - Dataset directory\n",
    "- `cat_to_name.json` - Category names mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68608bb3",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's verify that all necessary files are in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9618d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if required files exist\n",
    "required_files = ['train.py', 'predict.py', 'workspace_utils.py', 'cat_to_name.json']\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"✅ {file} found\")\n",
    "    else:\n",
    "        print(f\"❌ {file} not found\")\n",
    "\n",
    "# Check if flowers directory exists\n",
    "if os.path.exists('flowers'):\n",
    "    print(f\"✅ flowers/ directory found\")\n",
    "    # Check subdirectories\n",
    "    for subdir in ['train', 'valid', 'test']:\n",
    "        path = f'flowers/{subdir}'\n",
    "        if os.path.exists(path):\n",
    "            num_classes = len(os.listdir(path))\n",
    "            print(f\"   - {subdir}: {num_classes} classes\")\n",
    "else:\n",
    "    print(f\"❌ flowers/ directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25da54",
   "metadata": {},
   "source": [
    "## 2. Train the Model\n",
    "\n",
    "Train a VGG19 model on the flower dataset. This will take several minutes depending on your hardware.\n",
    "\n",
    "### Training Parameters:\n",
    "- Architecture: VGG19\n",
    "- Learning Rate: 0.001\n",
    "- Hidden Units: 512\n",
    "- Dropout: 0.3\n",
    "- Epochs: 5\n",
    "- GPU: Enabled (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5079df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training command\n",
    "train_command = [\n",
    "    'python3', 'train.py',\n",
    "    'flowers',                    # data directory\n",
    "    '--save_dir', 'checkpoint.pth',  # where to save the model\n",
    "    '--arch', 'vgg19',            # architecture\n",
    "    '--learning_rate', '0.001',   # learning rate\n",
    "    '--hidden_units', '512',      # hidden units\n",
    "    '--dropout', '0.3',           # dropout rate\n",
    "    '--epochs', '5',              # number of epochs\n",
    "    '--gpu',                      # use GPU\n",
    "    '--verbose'                   # verbose output\n",
    "]\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Command: {' '.join(train_command)}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Run the training script\n",
    "result = subprocess.run(train_command, capture_output=False, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ Training completed successfully!\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"❌ Training failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bd98b",
   "metadata": {},
   "source": [
    "## 3. Verify Checkpoint\n",
    "\n",
    "Check if the training checkpoint was created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoint.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    size_mb = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "    print(f\"✅ Checkpoint saved: {checkpoint_path}\")\n",
    "    print(f\"   Size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"❌ Checkpoint not found: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725b026",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "Use the trained model to predict flower classes for test images.\n",
    "\n",
    "### Prediction Parameters:\n",
    "- Top K: 5 (show top 5 predictions)\n",
    "- GPU: Enabled (if available)\n",
    "- Category names: Load from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a test image\n",
    "test_image = None\n",
    "test_dir = 'flowers/test'\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    # Get first available test image\n",
    "    for class_dir in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                test_image = os.path.join(class_path, images[0])\n",
    "                print(f\"Using test image: {test_image}\")\n",
    "                break\n",
    "\n",
    "if not test_image:\n",
    "    print(\"❌ No test images found!\")\n",
    "else:\n",
    "    # Prediction command\n",
    "    predict_command = [\n",
    "        'python3', 'predict.py',\n",
    "        test_image,                          # image to predict\n",
    "        'checkpoint.pth',                    # model checkpoint\n",
    "        '--category_names', 'cat_to_name.json',  # category names\n",
    "        '--top_k', '5',                      # top 5 predictions\n",
    "        '--gpu',                             # use GPU\n",
    "        '--verbose'                          # verbose output\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nCommand: {' '.join(predict_command)}\")\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "    # Run the prediction script\n",
    "    result = subprocess.run(predict_command, capture_output=False, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"✅ Prediction completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"❌ Prediction failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf702e7",
   "metadata": {},
   "source": [
    "## 5. Display Prediction Results\n",
    "\n",
    "View the generated prediction plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Find the most recent prediction image\n",
    "prediction_images = glob.glob('*_prediction.png')\n",
    "\n",
    "if prediction_images:\n",
    "    # Sort by modification time, get most recent\n",
    "    latest_prediction = max(prediction_images, key=os.path.getmtime)\n",
    "    print(f\"Displaying prediction: {latest_prediction}\\n\")\n",
    "    display(Image(filename=latest_prediction))\n",
    "else:\n",
    "    print(\"❌ No prediction images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d482e",
   "metadata": {},
   "source": [
    "## 6. Batch Predictions (Optional)\n",
    "\n",
    "Run predictions on multiple test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c35c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Collect multiple test images\n",
    "test_images = []\n",
    "test_dir = 'flowers/test'\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    for class_dir in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = [os.path.join(class_path, f) for f in os.listdir(class_path) \n",
    "                     if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                # Add one random image from this class\n",
    "                test_images.append(random.choice(images))\n",
    "\n",
    "# Limit to 5 images\n",
    "test_images = test_images[:5]\n",
    "\n",
    "print(f\"Running predictions on {len(test_images)} images...\\n\")\n",
    "\n",
    "for idx, image_path in enumerate(test_images, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Image {idx}/{len(test_images)}: {os.path.basename(image_path)}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    predict_command = [\n",
    "        'python3', 'predict.py',\n",
    "        image_path,\n",
    "        'checkpoint.pth',\n",
    "        '--category_names', 'cat_to_name.json',\n",
    "        '--top_k', '3',\n",
    "        '--gpu'\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(predict_command, capture_output=False, text=True)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✅ Batch predictions completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7379df",
   "metadata": {},
   "source": [
    "## 7. Alternative: Train with Different Architectures\n",
    "\n",
    "Compare different model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e531b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with ResNet18 (faster, smaller model)\n",
    "train_command_resnet = [\n",
    "    'python3', 'train.py',\n",
    "    'flowers',\n",
    "    '--save_dir', 'checkpoint_resnet18.pth',\n",
    "    '--arch', 'resnet18',         # Different architecture\n",
    "    '--learning_rate', '0.001',\n",
    "    '--hidden_units', '256',      # Smaller hidden layer\n",
    "    '--dropout', '0.3',\n",
    "    '--epochs', '5',\n",
    "    '--gpu'\n",
    "]\n",
    "\n",
    "print(\"Training ResNet18 model...\")\n",
    "print(f\"Command: {' '.join(train_command_resnet)}\")\n",
    "print(\"\\nNote: This is optional. Uncomment the line below to run.\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# subprocess.run(train_command_resnet, capture_output=False, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34356dab",
   "metadata": {},
   "source": [
    "## 8. Clean Up (Optional)\n",
    "\n",
    "Remove generated files if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up generated files\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # Remove checkpoint files\n",
    "# for checkpoint in glob.glob('checkpoint*.pth'):\n",
    "#     os.remove(checkpoint)\n",
    "#     print(f\"Removed: {checkpoint}\")\n",
    "\n",
    "# # Remove prediction images\n",
    "# for pred_img in glob.glob('*_prediction.png'):\n",
    "#     os.remove(pred_img)\n",
    "#     print(f\"Removed: {pred_img}\")\n",
    "\n",
    "print(\"Uncomment the code above to clean up files.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
